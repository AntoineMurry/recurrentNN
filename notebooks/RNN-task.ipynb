{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35cfea35f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = set([c for name in names for c in name] + [pad_token])### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {tokens[i]: i for i in range(len(tokens))} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id['#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[25 15 45 50 11 50 18 22 17]\n",
      " [25 34 22 51 23 41 17 17 17]\n",
      " [25  0 23 29 47 47 29 18 17]\n",
      " [25 34 29 51 52 50 14 14 18]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='tanh') ### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7f35cac74dd8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_num_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "x_t = input_sequence[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dense_2_16/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_17/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_18/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_19/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_20/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_21/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_22/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_23/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_24/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_25/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_26/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_27/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_28/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_29/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_30/Softmax:0' shape=(?, 56) dtype=float32>,\n",
       " <tf.Tensor 'dense_2_31/Softmax:0' shape=(?, 56) dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack_1:0' shape=(16, ?, 56) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack(predicted_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_1:0' shape=(?, 16, 56) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(tf.stack(predicted_probas), [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_69:0' shape=(?, 15, 56) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next to last token prediction is not needed\n",
    "predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_num_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_70:0' shape=(?, 15, 56) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1_31/Tanh:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_70:0' shape=(?, 15, 56) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_32:0' shape=(?, 56) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(predicted_probas, [-1, n_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_33:0' shape=(?,) dtype=int32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(input_sequence[:, 1:], [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_34:0' shape=(?, 56) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(?, 56) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = - 1 * tf.reduce_mean(answers_matrix * tf.log(predictions_matrix)) ### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49, 32, 27, 12, 27, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48],\n",
       "       [49, 21, 40, 24, 24, 40, 27, 48, 48, 48, 48, 48, 48, 48, 48, 48],\n",
       "       [49, 30, 52, 33,  9, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48]], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOlLVhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7468728ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall: this is training for comparison\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "# unroll the whole sequence for backprop\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Launcte\n",
      " Rhranan\n",
      " Kakti\n",
      " Tiaxe\n",
      " Llellest\n",
      " Ne\n",
      " Arsayz\n",
      " Scyene\n",
      " Cagitt\n",
      " Nhibtela\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Antoih\n",
      " Antoie\n",
      " Antoinie\n",
      " Antoike\n",
      " Antoi\n",
      " Antoicerl\n",
      " Antoide\n",
      " Antoi\n",
      " Antoino\n",
      " Antoia\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Antoi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Abagael',\n",
       " ' Abagail',\n",
       " ' Abbe',\n",
       " ' Abbey',\n",
       " ' Abbi',\n",
       " ' Abbie',\n",
       " ' Abby',\n",
       " ' Abigael',\n",
       " ' Abigail',\n",
       " ' Abigale',\n",
       " ' Abra',\n",
       " ' Acacia',\n",
       " ' Ada',\n",
       " ' Adah',\n",
       " ' Adaline',\n",
       " ' Adara',\n",
       " ' Addie',\n",
       " ' Addis',\n",
       " ' Adel',\n",
       " ' Adela',\n",
       " ' Adelaide',\n",
       " ' Adele',\n",
       " ' Adelice',\n",
       " ' Adelina',\n",
       " ' Adelind',\n",
       " ' Adeline',\n",
       " ' Adella',\n",
       " ' Adelle',\n",
       " ' Adena',\n",
       " ' Adey',\n",
       " ' Adi',\n",
       " ' Adiana',\n",
       " ' Adina',\n",
       " ' Adora',\n",
       " ' Adore',\n",
       " ' Adoree',\n",
       " ' Adorne',\n",
       " ' Adrea',\n",
       " ' Adria',\n",
       " ' Adriaens',\n",
       " ' Adrian',\n",
       " ' Adriana',\n",
       " ' Adriane',\n",
       " ' Adrianna',\n",
       " ' Adrianne',\n",
       " ' Adrien',\n",
       " ' Adriena',\n",
       " ' Adrienne',\n",
       " ' Aeriel',\n",
       " ' Aeriela',\n",
       " ' Aeriell',\n",
       " ' Ag',\n",
       " ' Agace',\n",
       " ' Agata',\n",
       " ' Agatha',\n",
       " ' Agathe',\n",
       " ' Aggi',\n",
       " ' Aggie',\n",
       " ' Aggy',\n",
       " ' Agna',\n",
       " ' Agnella',\n",
       " ' Agnes',\n",
       " ' Agnese',\n",
       " ' Agnesse',\n",
       " ' Agneta',\n",
       " ' Agnola',\n",
       " ' Agretha',\n",
       " ' Aida',\n",
       " ' Aidan',\n",
       " ' Aigneis',\n",
       " ' Aila',\n",
       " ' Aile',\n",
       " ' Ailee',\n",
       " ' Aileen',\n",
       " ' Ailene',\n",
       " ' Ailey',\n",
       " ' Aili',\n",
       " ' Ailina',\n",
       " ' Ailyn',\n",
       " ' Aime',\n",
       " ' Aimee',\n",
       " ' Aimil',\n",
       " ' Aina',\n",
       " ' Aindrea',\n",
       " ' Ainslee',\n",
       " ' Ainsley',\n",
       " ' Ainslie',\n",
       " ' Ajay',\n",
       " ' Alaine',\n",
       " ' Alameda',\n",
       " ' Alana',\n",
       " ' Alanah',\n",
       " ' Alane',\n",
       " ' Alanna',\n",
       " ' Alayne',\n",
       " ' Alberta',\n",
       " ' Albertina',\n",
       " ' Albertine',\n",
       " ' Albina',\n",
       " ' Alecia',\n",
       " ' Aleda',\n",
       " ' Aleece',\n",
       " ' Aleecia',\n",
       " ' Aleen',\n",
       " ' Alejandra',\n",
       " ' Alejandrina',\n",
       " ' Alena',\n",
       " ' Alene',\n",
       " ' Alessandra',\n",
       " ' Aleta',\n",
       " ' Alethea',\n",
       " ' Alex',\n",
       " ' Alexa',\n",
       " ' Alexandra',\n",
       " ' Alexandrina',\n",
       " ' Alexi',\n",
       " ' Alexia',\n",
       " ' Alexina',\n",
       " ' Alexine',\n",
       " ' Alexis',\n",
       " ' Alfie',\n",
       " ' Alfreda',\n",
       " ' Ali',\n",
       " ' Alia',\n",
       " ' Alica',\n",
       " ' Alice',\n",
       " ' Alicea',\n",
       " ' Alicia',\n",
       " ' Alida',\n",
       " ' Alidia',\n",
       " ' Alina',\n",
       " ' Aline',\n",
       " ' Alis',\n",
       " ' Alisa',\n",
       " ' Alisha',\n",
       " ' Alison',\n",
       " ' Alissa',\n",
       " ' Alisun',\n",
       " ' Alix',\n",
       " ' Aliza',\n",
       " ' Alla',\n",
       " ' Alleen',\n",
       " ' Allegra',\n",
       " ' Allene',\n",
       " ' Alli',\n",
       " ' Allianora',\n",
       " ' Allie',\n",
       " ' Allina',\n",
       " ' Allis',\n",
       " ' Allison',\n",
       " ' Allissa',\n",
       " ' Allsun',\n",
       " ' Ally',\n",
       " ' Allyce',\n",
       " ' Allyn',\n",
       " ' Allys',\n",
       " ' Allyson',\n",
       " ' Alma',\n",
       " ' Almeda',\n",
       " ' Almeria',\n",
       " ' Almeta',\n",
       " ' Almira',\n",
       " ' Almire',\n",
       " ' Aloise',\n",
       " ' Aloisia',\n",
       " ' Aloysia',\n",
       " ' Alpa',\n",
       " ' Alta',\n",
       " ' Althea',\n",
       " ' Alvera',\n",
       " ' Alvina',\n",
       " ' Alvinia',\n",
       " ' Alvira',\n",
       " ' Alyce',\n",
       " ' Alyda',\n",
       " ' Alys',\n",
       " ' Alysa',\n",
       " ' Alyse',\n",
       " ' Alysia',\n",
       " ' Alyson',\n",
       " ' Alyss',\n",
       " ' Alyssa',\n",
       " ' Amabel',\n",
       " ' Amabelle',\n",
       " ' Amalea',\n",
       " ' Amalee',\n",
       " ' Amaleta',\n",
       " ' Amalia',\n",
       " ' Amalie',\n",
       " ' Amalita',\n",
       " ' Amalle',\n",
       " ' Amanda',\n",
       " ' Amandi',\n",
       " ' Amandie',\n",
       " ' Amandy',\n",
       " ' Amara',\n",
       " ' Amargo',\n",
       " ' Amata',\n",
       " ' Amber',\n",
       " ' Amberly',\n",
       " ' Ambrosia',\n",
       " ' Ambur',\n",
       " ' Ame',\n",
       " ' Amelia',\n",
       " ' Amelie',\n",
       " ' Amelina',\n",
       " ' Ameline',\n",
       " ' Amelita',\n",
       " ' Ami',\n",
       " ' Amie',\n",
       " ' Amity',\n",
       " ' Ammamaria',\n",
       " ' Amy',\n",
       " ' Ana',\n",
       " ' Anabel',\n",
       " ' Anabella',\n",
       " ' Anabelle',\n",
       " ' Anais',\n",
       " ' Analiese',\n",
       " ' Analise',\n",
       " ' Anallese',\n",
       " ' Anallise',\n",
       " ' Anastasia',\n",
       " ' Anastasie',\n",
       " ' Anastassia',\n",
       " ' Anatola',\n",
       " ' Andee',\n",
       " ' Andi',\n",
       " ' Andie',\n",
       " ' Andra',\n",
       " ' Andrea',\n",
       " ' Andreana',\n",
       " ' Andree',\n",
       " ' Andrei',\n",
       " ' Andria',\n",
       " ' Andriana',\n",
       " ' Andriette',\n",
       " ' Andromache',\n",
       " ' Andromeda',\n",
       " ' Andy',\n",
       " ' Anestassia',\n",
       " ' Anet',\n",
       " ' Anett',\n",
       " ' Anetta',\n",
       " ' Anette',\n",
       " ' Ange',\n",
       " ' Angel',\n",
       " ' Angela',\n",
       " ' Angele',\n",
       " ' Angelia',\n",
       " ' Angelica',\n",
       " ' Angelika',\n",
       " ' Angelina',\n",
       " ' Angeline',\n",
       " ' Angelique',\n",
       " ' Angelita',\n",
       " ' Angelle',\n",
       " ' Angie',\n",
       " ' Angil',\n",
       " ' Angy',\n",
       " ' Ania',\n",
       " ' Anica',\n",
       " ' Anissa',\n",
       " ' Anita',\n",
       " ' Anitra',\n",
       " ' Anja',\n",
       " ' Anjanette',\n",
       " ' Anjela',\n",
       " ' Ann',\n",
       " ' Ann-Mari',\n",
       " ' Ann-Marie',\n",
       " ' Anna',\n",
       " ' Anna-Diana',\n",
       " ' Anna-Diane',\n",
       " ' Anna-Maria',\n",
       " ' Annabal',\n",
       " ' Annabel',\n",
       " ' Annabela',\n",
       " ' Annabell',\n",
       " ' Annabella',\n",
       " ' Annabelle',\n",
       " ' Annadiana',\n",
       " ' Annadiane',\n",
       " ' Annalee',\n",
       " ' Annalena',\n",
       " ' Annaliese',\n",
       " ' Annalisa',\n",
       " ' Annalise',\n",
       " ' Annalyse',\n",
       " ' Annamari',\n",
       " ' Annamaria',\n",
       " ' Annamarie',\n",
       " ' Anne',\n",
       " ' Anne-Corinne',\n",
       " ' Anne-Mar',\n",
       " ' Anne-Marie',\n",
       " ' Annecorinne',\n",
       " ' Anneliese',\n",
       " ' Annelise',\n",
       " ' Annemarie',\n",
       " ' Annetta',\n",
       " ' Annette',\n",
       " ' Anni',\n",
       " ' Annice',\n",
       " ' Annie',\n",
       " ' Annissa',\n",
       " ' Annmaria',\n",
       " ' Annmarie',\n",
       " ' Annnora',\n",
       " ' Annora',\n",
       " ' Anny',\n",
       " ' Anselma',\n",
       " ' Ansley',\n",
       " ' Anstice',\n",
       " ' Anthe',\n",
       " ' Anthea',\n",
       " ' Anthia',\n",
       " ' Antoinette',\n",
       " ' Antonella',\n",
       " ' Antonetta',\n",
       " ' Antonia',\n",
       " ' Antonie',\n",
       " ' Antonietta',\n",
       " ' Antonina',\n",
       " ' Anya',\n",
       " ' Aphrodite',\n",
       " ' Appolonia',\n",
       " ' April',\n",
       " ' Aprilette',\n",
       " ' Ara',\n",
       " ' Arabel',\n",
       " ' Arabela',\n",
       " ' Arabele',\n",
       " ' Arabella',\n",
       " ' Arabelle',\n",
       " ' Arda',\n",
       " ' Ardath',\n",
       " ' Ardeen',\n",
       " ' Ardelia',\n",
       " ' Ardelis',\n",
       " ' Ardella',\n",
       " ' Ardelle',\n",
       " ' Arden',\n",
       " ' Ardene',\n",
       " ' Ardenia',\n",
       " ' Ardine',\n",
       " ' Ardis',\n",
       " ' Ardith',\n",
       " ' Ardra',\n",
       " ' Ardyce',\n",
       " ' Ardys',\n",
       " ' Ardyth',\n",
       " ' Aretha',\n",
       " ' Ariadne',\n",
       " ' Ariana',\n",
       " ' Arianne',\n",
       " ' Aridatha',\n",
       " ' Ariel',\n",
       " ' Ariela',\n",
       " ' Ariella',\n",
       " ' Arielle',\n",
       " ' Arlana',\n",
       " ' Arlee',\n",
       " ' Arleen',\n",
       " ' Arlen',\n",
       " ' Arlena',\n",
       " ' Arlene',\n",
       " ' Arleta',\n",
       " ' Arlette',\n",
       " ' Arleyne',\n",
       " ' Arlie',\n",
       " ' Arliene',\n",
       " ' Arlina',\n",
       " ' Arlinda',\n",
       " ' Arline',\n",
       " ' Arly',\n",
       " ' Arlyn',\n",
       " ' Arlyne',\n",
       " ' Aryn',\n",
       " ' Ashely',\n",
       " ' Ashlee',\n",
       " ' Ashleigh',\n",
       " ' Ashlen',\n",
       " ' Ashley',\n",
       " ' Ashli',\n",
       " ' Ashlie',\n",
       " ' Ashly',\n",
       " ' Asia',\n",
       " ' Astra',\n",
       " ' Astrid',\n",
       " ' Astrix',\n",
       " ' Atalanta',\n",
       " ' Athena',\n",
       " ' Athene',\n",
       " ' Atlanta',\n",
       " ' Atlante',\n",
       " ' Auberta',\n",
       " ' Aubine',\n",
       " ' Aubree',\n",
       " ' Aubrette',\n",
       " ' Aubrey',\n",
       " ' Aubrie',\n",
       " ' Aubry',\n",
       " ' Audi',\n",
       " ' Audie',\n",
       " ' Audra',\n",
       " ' Audre',\n",
       " ' Audrey',\n",
       " ' Audrie',\n",
       " ' Audry',\n",
       " ' Audrye',\n",
       " ' Audy',\n",
       " ' Augusta',\n",
       " ' Auguste',\n",
       " ' Augustina',\n",
       " ' Augustine',\n",
       " ' Aura',\n",
       " ' Aurea',\n",
       " ' Aurel',\n",
       " ' Aurelea',\n",
       " ' Aurelia',\n",
       " ' Aurelie',\n",
       " ' Auria',\n",
       " ' Aurie',\n",
       " ' Aurilia',\n",
       " ' Aurlie',\n",
       " ' Auroora',\n",
       " ' Aurora',\n",
       " ' Aurore',\n",
       " ' Austin',\n",
       " ' Austina',\n",
       " ' Austine',\n",
       " ' Ava',\n",
       " ' Aveline',\n",
       " ' Averil',\n",
       " ' Averyl',\n",
       " ' Avie',\n",
       " ' Avis',\n",
       " ' Aviva',\n",
       " ' Avivah',\n",
       " ' Avril',\n",
       " ' Avrit',\n",
       " ' Ayn',\n",
       " ' Bab',\n",
       " ' Babara',\n",
       " ' Babette',\n",
       " ' Babita',\n",
       " ' Babs',\n",
       " ' Bambi',\n",
       " ' Bambie',\n",
       " ' Bamby',\n",
       " ' Barb',\n",
       " ' Barbabra',\n",
       " ' Barbara',\n",
       " ' Barbara-Anne',\n",
       " ' Barbaraanne',\n",
       " ' Barbe',\n",
       " ' Barbee',\n",
       " ' Barbette',\n",
       " ' Barbey',\n",
       " ' Barbi',\n",
       " ' Barbie',\n",
       " ' Barbra',\n",
       " ' Barby',\n",
       " ' Bari',\n",
       " ' Barrie',\n",
       " ' Barry',\n",
       " ' Basia',\n",
       " ' Bathsheba',\n",
       " ' Batsheva',\n",
       " ' Bea',\n",
       " ' Beatrice',\n",
       " ' Beatrisa',\n",
       " ' Beatrix',\n",
       " ' Beatriz',\n",
       " ' Beau',\n",
       " ' Bebe',\n",
       " ' Becca',\n",
       " ' Becka',\n",
       " ' Becki',\n",
       " ' Beckie',\n",
       " ' Becky',\n",
       " ' Bee',\n",
       " ' Beilul',\n",
       " ' Beitris',\n",
       " ' Bekki',\n",
       " ' Bel',\n",
       " ' Belia',\n",
       " ' Belicia',\n",
       " ' Belinda',\n",
       " ' Belita',\n",
       " ' Bell',\n",
       " ' Bella',\n",
       " ' Bellamy',\n",
       " ' Bellanca',\n",
       " ' Belle',\n",
       " ' Bellina',\n",
       " ' Belva',\n",
       " ' Belvia',\n",
       " ' Bendite',\n",
       " ' Benedetta',\n",
       " ' Benedicta',\n",
       " ' Benedikta',\n",
       " ' Benetta',\n",
       " ' Benita',\n",
       " ' Benni',\n",
       " ' Bennie',\n",
       " ' Benny',\n",
       " ' Benoite',\n",
       " ' Berenice',\n",
       " ' Beret',\n",
       " ' Berget',\n",
       " ' Berna',\n",
       " ' Bernadene',\n",
       " ' Bernadette',\n",
       " ' Bernadina',\n",
       " ' Bernadine',\n",
       " ' Bernardina',\n",
       " ' Bernardine',\n",
       " ' Bernelle',\n",
       " ' Bernete',\n",
       " ' Bernetta',\n",
       " ' Bernette',\n",
       " ' Berni',\n",
       " ' Bernice',\n",
       " ' Bernie',\n",
       " ' Bernita',\n",
       " ' Berny',\n",
       " ' Berri',\n",
       " ' Berrie',\n",
       " ' Berry',\n",
       " ' Bert',\n",
       " ' Berta',\n",
       " ' Berte',\n",
       " ' Bertha',\n",
       " ' Berthe',\n",
       " ' Berti',\n",
       " ' Bertie',\n",
       " ' Bertina',\n",
       " ' Bertine',\n",
       " ' Berty',\n",
       " ' Beryl',\n",
       " ' Beryle',\n",
       " ' Bess',\n",
       " ' Bessie',\n",
       " ' Bessy',\n",
       " ' Beth',\n",
       " ' Bethanne',\n",
       " ' Bethany',\n",
       " ' Bethena',\n",
       " ' Bethina',\n",
       " ' Betsey',\n",
       " ' Betsy',\n",
       " ' Betta',\n",
       " ' Bette',\n",
       " ' Bette-Ann',\n",
       " ' Betteann',\n",
       " ' Betteanne',\n",
       " ' Betti',\n",
       " ' Bettie',\n",
       " ' Bettina',\n",
       " ' Bettine',\n",
       " ' Betty',\n",
       " ' Bettye',\n",
       " ' Beulah',\n",
       " ' Bev',\n",
       " ' Beverie',\n",
       " ' Beverlee',\n",
       " ' Beverlie',\n",
       " ' Beverly',\n",
       " ' Bevvy',\n",
       " ' Bianca',\n",
       " ' Bianka',\n",
       " ' Biddy',\n",
       " ' Bidget',\n",
       " ' Bill',\n",
       " ' Billi',\n",
       " ' Billie',\n",
       " ' Billy',\n",
       " ' Binni',\n",
       " ' Binnie',\n",
       " ' Binny',\n",
       " ' Bird',\n",
       " ' Birdie',\n",
       " ' Birgit',\n",
       " ' Birgitta',\n",
       " ' Blair',\n",
       " ' Blaire',\n",
       " ' Blake',\n",
       " ' Blakelee',\n",
       " ' Blakeley',\n",
       " ' Blanca',\n",
       " ' Blanch',\n",
       " ' Blancha',\n",
       " ' Blanche',\n",
       " ' Blinni',\n",
       " ' Blinnie',\n",
       " ' Blinny',\n",
       " ' Bliss',\n",
       " ' Blisse',\n",
       " ' Blithe',\n",
       " ' Blondell',\n",
       " ' Blondelle',\n",
       " ' Blondie',\n",
       " ' Blondy',\n",
       " ' Blythe',\n",
       " ' Bo',\n",
       " ' Bobbette',\n",
       " ' Bobbi',\n",
       " ' Bobbie',\n",
       " ' Bobby',\n",
       " ' Bobette',\n",
       " ' Bobina',\n",
       " ' Bobine',\n",
       " ' Bobinette',\n",
       " ' Bonita',\n",
       " ' Bonnee',\n",
       " ' Bonni',\n",
       " ' Bonnie',\n",
       " ' Bonny',\n",
       " ' Brana',\n",
       " ' Brandais',\n",
       " ' Brande',\n",
       " ' Brandea',\n",
       " ' Brandi',\n",
       " ' Brandice',\n",
       " ' Brandie',\n",
       " ' Brandise',\n",
       " ' Brandy',\n",
       " ' Brea',\n",
       " ' Breanne',\n",
       " ' Brear',\n",
       " ' Bree',\n",
       " ' Breena',\n",
       " ' Bren',\n",
       " ' Brena',\n",
       " ' Brenda',\n",
       " ' Brenn',\n",
       " ' Brenna',\n",
       " ' Brett',\n",
       " ' Bria',\n",
       " ' Briana',\n",
       " ' Brianna',\n",
       " ' Brianne',\n",
       " ' Bride',\n",
       " ' Bridget',\n",
       " ' Bridgett',\n",
       " ' Bridgette',\n",
       " ' Bridie',\n",
       " ' Brier',\n",
       " ' Brietta',\n",
       " ' Brigid',\n",
       " ' Brigida',\n",
       " ' Brigit',\n",
       " ' Brigitta',\n",
       " ' Brigitte',\n",
       " ' Brina',\n",
       " ' Briney',\n",
       " ' Briny',\n",
       " ' Brit',\n",
       " ' Brita',\n",
       " ' Britaney',\n",
       " ' Britani',\n",
       " ' Briteny',\n",
       " ' Britney',\n",
       " ' Britni',\n",
       " ' Britt',\n",
       " ' Britta',\n",
       " ' Brittan',\n",
       " ' Brittany',\n",
       " ' Britte',\n",
       " ' Brittney',\n",
       " ' Brook',\n",
       " ' Brooke',\n",
       " ' Brooks',\n",
       " ' Brunella',\n",
       " ' Brunhilda',\n",
       " ' Brunhilde',\n",
       " ' Bryana',\n",
       " ' Bryn',\n",
       " ' Bryna',\n",
       " ' Brynn',\n",
       " ' Brynna',\n",
       " ' Brynne',\n",
       " ' Buffy',\n",
       " ' Bunni',\n",
       " ' Bunnie',\n",
       " ' Bunny',\n",
       " ' Burta',\n",
       " ' Cabrina',\n",
       " ' Cacilia',\n",
       " ' Cacilie',\n",
       " ' Caitlin',\n",
       " ' Caitrin',\n",
       " ' Cal',\n",
       " ' Calida',\n",
       " ' Calla',\n",
       " ' Calley',\n",
       " ' Calli',\n",
       " ' Callida',\n",
       " ' Callie',\n",
       " ' Cally',\n",
       " ' Calypso',\n",
       " ' Cam',\n",
       " ' Camala',\n",
       " ' Camel',\n",
       " ' Camella',\n",
       " ' Camellia',\n",
       " ' Cameo',\n",
       " ' Cami',\n",
       " ' Camila',\n",
       " ' Camile',\n",
       " ' Camilla',\n",
       " ' Camille',\n",
       " ' Cammi',\n",
       " ' Cammie',\n",
       " ' Cammy',\n",
       " ' Canada',\n",
       " ' Candace',\n",
       " ' Candi',\n",
       " ' Candice',\n",
       " ' Candida',\n",
       " ' Candide',\n",
       " ' Candie',\n",
       " ' Candis',\n",
       " ' Candra',\n",
       " ' Candy',\n",
       " ' Cappella',\n",
       " ' Caprice',\n",
       " ' Cara',\n",
       " ' Caralie',\n",
       " ' Caren',\n",
       " ' Carena',\n",
       " ' Caresa',\n",
       " ' Caressa',\n",
       " ' Caresse',\n",
       " ' Carey',\n",
       " ' Cari',\n",
       " ' Caria',\n",
       " ' Carie',\n",
       " ' Caril',\n",
       " ' Carilyn',\n",
       " ' Carin',\n",
       " ' Carina',\n",
       " ' Carine',\n",
       " ' Cariotta',\n",
       " ' Carissa',\n",
       " ' Carita',\n",
       " ' Caritta',\n",
       " ' Carla',\n",
       " ' Carlee',\n",
       " ' Carleen',\n",
       " ' Carlen',\n",
       " ' Carlena',\n",
       " ' Carlene',\n",
       " ' Carley',\n",
       " ' Carli',\n",
       " ' Carlie',\n",
       " ' Carlin',\n",
       " ' Carlina',\n",
       " ' Carline',\n",
       " ' Carlisle',\n",
       " ' Carlita',\n",
       " ' Carlota',\n",
       " ' Carlotta',\n",
       " ' Carly',\n",
       " ' Carlye',\n",
       " ' Carlyn',\n",
       " ' Carlynn',\n",
       " ' Carlynne',\n",
       " ' Carma',\n",
       " ' Carmel',\n",
       " ' Carmela',\n",
       " ' Carmelia',\n",
       " ' Carmelina',\n",
       " ' Carmelita',\n",
       " ' Carmella',\n",
       " ' Carmelle',\n",
       " ' Carmen',\n",
       " ' Carmina',\n",
       " ' Carmine',\n",
       " ' Carmita',\n",
       " ' Carmon',\n",
       " ' Caro',\n",
       " ' Carol',\n",
       " ' Carol-Jean',\n",
       " ' Carola',\n",
       " ' Carolan',\n",
       " ' Carolann',\n",
       " ' Carole',\n",
       " ' Carolee',\n",
       " ' Caroleen',\n",
       " ' Carolie',\n",
       " ' Carolin',\n",
       " ' Carolina',\n",
       " ' Caroline',\n",
       " ' Caroljean',\n",
       " ' Carolyn',\n",
       " ' Carolyne',\n",
       " ' Carolynn',\n",
       " ' Caron',\n",
       " ' Carree',\n",
       " ' Carri',\n",
       " ' Carrie',\n",
       " ' Carrissa',\n",
       " ' Carrol',\n",
       " ' Carroll',\n",
       " ' Carry',\n",
       " ' Cary',\n",
       " ' Caryl',\n",
       " ' Caryn',\n",
       " ' Casandra',\n",
       " ' Casey',\n",
       " ' Casi',\n",
       " ' Casia',\n",
       " ' Casie',\n",
       " ' Cass',\n",
       " ' Cassandra',\n",
       " ' Cassandre',\n",
       " ' Cassandry',\n",
       " ' Cassaundra',\n",
       " ' Cassey',\n",
       " ' Cassi',\n",
       " ' Cassie',\n",
       " ' Cassondra',\n",
       " ' Cassy',\n",
       " ' Cat',\n",
       " ' Catarina',\n",
       " ' Cate',\n",
       " ' Caterina',\n",
       " ' Catha',\n",
       " ' Catharina',\n",
       " ' Catharine',\n",
       " ' Cathe',\n",
       " ' Cathee',\n",
       " ' Catherin',\n",
       " ' Catherina',\n",
       " ' Catherine',\n",
       " ' Cathi',\n",
       " ' Cathie',\n",
       " ' Cathleen',\n",
       " ' Cathlene',\n",
       " ' Cathrin',\n",
       " ' Cathrine',\n",
       " ' Cathryn',\n",
       " ' Cathy',\n",
       " ' Cathyleen',\n",
       " ' Cati',\n",
       " ' Catie',\n",
       " ' Catina',\n",
       " ' Catlaina',\n",
       " ' Catlee',\n",
       " ' Catlin',\n",
       " ' Catrina',\n",
       " ' Catriona',\n",
       " ' Caty',\n",
       " ' Cayla',\n",
       " ' Cecelia',\n",
       " ' Cecil',\n",
       " ' Cecile',\n",
       " ' Ceciley',\n",
       " ' Cecilia',\n",
       " ' Cecilla',\n",
       " ' Cecily',\n",
       " ' Ceil',\n",
       " ' Cele',\n",
       " ' Celene',\n",
       " ' Celesta',\n",
       " ' Celeste',\n",
       " ' Celestia',\n",
       " ' Celestina',\n",
       " ' Celestine',\n",
       " ' Celestyn',\n",
       " ' Celestyna',\n",
       " ' Celia',\n",
       " ' Celie',\n",
       " ' Celina',\n",
       " ' Celinda',\n",
       " ' Celine',\n",
       " ' Celinka',\n",
       " ' Celisse',\n",
       " ' Celle',\n",
       " ' Cesya',\n",
       " ' Chad',\n",
       " ' Chanda',\n",
       " ' Chandal',\n",
       " ' Chandra',\n",
       " ' Channa',\n",
       " ' Chantal',\n",
       " ' Chantalle',\n",
       " ' Charil',\n",
       " ' Charin',\n",
       " ' Charis',\n",
       " ' Charissa',\n",
       " ' Charisse',\n",
       " ' Charita',\n",
       " ' Charity',\n",
       " ' Charla',\n",
       " ' Charlean',\n",
       " ' Charleen',\n",
       " ' Charlena',\n",
       " ' Charlene',\n",
       " ' Charline',\n",
       " ' Charlot',\n",
       " ' Charlott',\n",
       " ' Charlotta',\n",
       " ' Charlotte',\n",
       " ' Charmain',\n",
       " ' Charmaine',\n",
       " ' Charmane',\n",
       " ' Charmian',\n",
       " ' Charmine',\n",
       " ' Charmion',\n",
       " ' Charo',\n",
       " ' Charyl',\n",
       " ' Chastity',\n",
       " ' Chelsae',\n",
       " ' Chelsea',\n",
       " ' Chelsey',\n",
       " ' Chelsie',\n",
       " ' Chelsy',\n",
       " ' Cher',\n",
       " ' Chere',\n",
       " ' Cherey',\n",
       " ' Cheri',\n",
       " ' Cherianne',\n",
       " ' Cherice',\n",
       " ' Cherida',\n",
       " ' Cherie',\n",
       " ' Cherilyn',\n",
       " ' Cherilynn',\n",
       " ' Cherin',\n",
       " ' Cherise',\n",
       " ' Cherish',\n",
       " ' Cherlyn',\n",
       " ' Cherri',\n",
       " ' Cherrita',\n",
       " ' Cherry',\n",
       " ' Chery',\n",
       " ' Cherye',\n",
       " ' Cheryl',\n",
       " ' Cheslie',\n",
       " ' Chiarra',\n",
       " ' Chickie',\n",
       " ' Chicky',\n",
       " ' Chiquita',\n",
       " ' Chloe',\n",
       " ' Chloette',\n",
       " ' Chloris',\n",
       " ' Chris',\n",
       " ' Chriss',\n",
       " ' Chrissa',\n",
       " ' Chrissie',\n",
       " ' Chrissy',\n",
       " ' Christa',\n",
       " ' Christabel',\n",
       " ' Christabella',\n",
       " ' Christabelle',\n",
       " ' Christal',\n",
       " ' Christalle',\n",
       " ' Christan',\n",
       " ' Christean',\n",
       " ' Christel',\n",
       " ' Christen',\n",
       " ' Christi',\n",
       " ' Christian',\n",
       " ' Christiana',\n",
       " ' Christiane',\n",
       " ' Christie',\n",
       " ' Christin',\n",
       " ' Christina',\n",
       " ' Christine',\n",
       " ' Christy',\n",
       " ' Christyna',\n",
       " ' Chrysa',\n",
       " ' Chrysler',\n",
       " ' Chrystal',\n",
       " ' Chryste',\n",
       " ' Chrystel',\n",
       " ' Ciara',\n",
       " ' Cicely',\n",
       " ' Cicily',\n",
       " ' Ciel',\n",
       " ' Cilka',\n",
       " ' Cinda',\n",
       " ' Cindee',\n",
       " ' Cindelyn',\n",
       " ' Cinderella',\n",
       " ' Cindi',\n",
       " ' Cindie',\n",
       " ' Cindra',\n",
       " ' Cindy',\n",
       " ' Cinnamon',\n",
       " ' Cissie',\n",
       " ' Cissy',\n",
       " ' Clair',\n",
       " ' Claire',\n",
       " ' Clara',\n",
       " ' Clarabelle',\n",
       " ' Clare',\n",
       " ...]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"kfL3YSNZHCzAiaB4\"\n",
    "COURSERA_EMAIL = \"antoine.murry1992@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1371cddf86544b94b28e49faf703b140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
